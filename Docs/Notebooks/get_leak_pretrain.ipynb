{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "# root_dir = str(pathlib.Path(__file__).resolve().parents[2])\n",
    "# sys.path.append(root_dir)\n",
    "os.chdir(\"/home/labhhc1/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing SMILES: 100%|██████████| 152/152 [00:00<00:00, 445.81it/s]\n",
      "Standardizing SMILES: 100%|██████████| 204/204 [00:00<00:00, 14233.83it/s]\n",
      "[15:24:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:24:02] WARNING: not removing hydrogen atom without neighbors\n",
      "Standardizing SMILES: 100%|██████████| 143/143 [00:00<00:00, 14758.86it/s]\n",
      "Standardizing SMILES: 100%|██████████| 148/148 [00:00<00:00, 14906.63it/s]\n",
      "Standardizing SMILES: 100%|██████████| 784/784 [00:00<00:00, 15332.66it/s]\n",
      "Standardizing SMILES: 100%|██████████| 858/858 [00:00<00:00, 17645.16it/s]\n",
      "Standardizing SMILES: 100%|██████████| 4113/4113 [00:00<00:00, 15174.15it/s]\n",
      "Standardizing SMILES: 100%|██████████| 9309/9309 [00:00<00:00, 17194.66it/s]\n",
      "Standardizing SMILES: 100%|██████████| 113/113 [00:00<00:00, 11997.68it/s]\n",
      "Standardizing SMILES: 100%|██████████| 65/65 [00:00<00:00, 12928.81it/s]\n",
      "Standardizing SMILES: 100%|██████████| 420/420 [00:00<00:00, 15654.14it/s]\n",
      "Standardizing SMILES: 100%|██████████| 683/683 [00:00<00:00, 22995.49it/s]\n",
      "Standardizing SMILES: 100%|██████████| 2179/2179 [00:00<00:00, 20747.34it/s]\n",
      "Standardizing SMILES:   0%|          | 0/13389 [00:00<?, ?it/s][15:24:04] Can't kekulize mol.  Unkekulized atoms: 1 5\n",
      "Standardizing SMILES: 100%|██████████| 13389/13389 [00:00<00:00, 24005.40it/s]\n",
      "[15:24:05] Can't kekulize mol.  Unkekulized atoms: 1 5\n"
     ]
    }
   ],
   "source": [
    "from KGGraph.KGGChem.standardize import SmileStandardizer\n",
    "dataset_name=[\"bace\", \"bbbp\", \"sider\", \"clintox\", \"tox21\", \"toxcast\", \"hiv\", \"muv\", \"esol\", \"freesolv\", \"lipo\", \"qm7\", \"qm8\", \"qm9\"]\n",
    "for dataset in dataset_name:\n",
    "    SmileStandardizer.standardize(f\"Data/contamination/test_{dataset}.txt\", f\"Data/cleanup/standsmi_test_{dataset}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two million pretrain datasets has 0 compounds in common with test bace with len 152\n",
      "Two million pretrain datasets has 0 compounds in common with test bbbp with len 204\n",
      "Two million pretrain datasets has 0 compounds in common with test sider with len 143\n",
      "Two million pretrain datasets has 2 compounds in common with test clintox with len 148\n",
      "Two million pretrain datasets has 2 compounds in common with test tox21 with len 784\n",
      "Two million pretrain datasets has 2 compounds in common with test toxcast with len 858\n",
      "Two million pretrain datasets has 13 compounds in common with test hiv with len 4113\n",
      "Two million pretrain datasets has 56 compounds in common with test muv with len 9309\n",
      "Two million pretrain datasets has 0 compounds in common with test esol with len 113\n",
      "Two million pretrain datasets has 0 compounds in common with test freesolv with len 65\n",
      "Two million pretrain datasets has 0 compounds in common with test lipo with len 420\n",
      "Two million pretrain datasets has 0 compounds in common with test qm7 with len 683\n",
      "Two million pretrain datasets has 0 compounds in common with test qm8 with len 2179\n",
      "Two million pretrain datasets has 0 compounds in common with test qm9 with len 13389\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_name:\n",
    "    with open(f\"Data/cleanup/standsmi_test_{dataset}.txt\", 'r') as f:\n",
    "        test_data = [line.strip(\"\\r\\n\").split()[0] for line in f]\n",
    "    with open(\"Data/cleanup/standsmi_zinc.txt\", 'r') as f:\n",
    "        twomil_pretrain_data = [line.strip(\"\\r\\n\").split()[0] for line in f]\n",
    "\n",
    "    # Assuming test_data, twomil, and tenmil are lists\n",
    "    test_data_set = set(test_data)\n",
    "    twomil_set = set(twomil_pretrain_data)\n",
    "    # tenmil_set = set(tenmil_pretrain_data)\n",
    "\n",
    "    # Find the intersection\n",
    "    intersection_1 = test_data_set.intersection(twomil_set)\n",
    "    # intersection_2 = test_data_set.intersection(tenmil_set)\n",
    "\n",
    "    # Print the intersection\n",
    "    print(\"Two million pretrain datasets has\", len(intersection_1), f\"compounds in common with test {dataset} with len\", len(test_data))\n",
    "    # with open(\"Data/cleanup/standsmi_pubchem.txt\", \"r\") as f:\n",
    "    #     tenmil_pretrain_data = [line.strip(\"\\r\\n\").split()[0] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two million pretrain datasets has 1514 compounds in common with test data with len 2289\n",
      "Ten million pretrain datasets has 73 compounds in common with test data with len 2289\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_data, twomil, and tenmil are lists\n",
    "test_data_set = set(test_data)\n",
    "twomil_set = set(twomil_pretrain_data)\n",
    "# tenmil_set = set(tenmil_pretrain_data)\n",
    "\n",
    "# Find the intersection\n",
    "intersection_1 = test_data_set.intersection(twomil_set)\n",
    "# intersection_2 = test_data_set.intersection(tenmil_set)\n",
    "\n",
    "# Print the intersection\n",
    "print(\"Two million pretrain datasets has\", len(intersection_1), \"compounds in common with test data with len\", len(test_data))\n",
    "# print(\"Ten million pretrain datasets has\", len(intersection_2), \"compounds in common with test data with len\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/zinc/all_inter_2m.txt\", \"a\") as f:\n",
    "        f.writelines(\"%s\\n\" % s for s in intersection_1)\n",
    "with open(\"Data/zinc/all_inter_10m.txt\", \"a\") as f:\n",
    "        f.writelines(\"%s\\n\" % s for s in intersection_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
