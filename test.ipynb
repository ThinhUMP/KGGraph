{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter, BatchNorm1d\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_scatter import scatter_add\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "\n",
    "unique_value_edge_attr = 2\n",
    "\n",
    "class GINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Extension of GIN aggregation to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): dimensionality of embeddings for nodes and edges.\n",
    "        embed_input (bool): whether to embed input or not. \n",
    "        \n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, emb_dim, aggr = \"add\"):\n",
    "        super(GINConv, self).__init__()\n",
    "        #multi-layer perceptron\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, 2*emb_dim),\n",
    "            torch.nn.BatchNorm1d(2*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2*emb_dim, 4*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4*emb_dim, 2*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            )\n",
    "        self.edge_embedding = torch.nn.Embedding(unique_value_edge_attr, in_channels)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding.weight.data)\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #add self loops in the edge space\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        #add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), edge_attr.size(1))\n",
    "        self_loop_attr[:,-4] = 1 #bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim = 0)\n",
    "\n",
    "        edge_embeddings = torch.zeros((edge_attr.size(0), self.in_channels), dtype=torch.float).to(edge_attr.device).to(edge_attr.dtype)\n",
    "\n",
    "        for i in range(edge_attr.size(1)):  # Iterate over the second dimension\n",
    "            embedding_ith = self.edge_embedding(edge_attr[:, i]).clone().detach().to(edge_attr.device).to(edge_attr.dtype)\n",
    "            edge_embeddings += embedding_ith\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        print(x_j.shape, edge_attr.shape)\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        print(aggr_out.size())\n",
    "        aggr_out = torch.tensor(aggr_out, dtype=torch.float)\n",
    "        return self.mlp(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3]) torch.Size([9, 3])\n",
      "torch.Size([4, 3])\n",
      "Original node features:\n",
      " tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "\n",
      "Transformed node features:\n",
      " torch.Size([4, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124099/1986989193.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  aggr_out = torch.tensor(aggr_out, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Initialize the GCNConv layer\n",
    "# Transform from 3-dimensional features to 2-dimensional features\n",
    "gin_conv = GINConv(in_channels=3, emb_dim=6)\n",
    "\n",
    "# Define node features (4 nodes with 3 features each)\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], dtype=torch.float)\n",
    "\n",
    "# Define the edges in the graph (making it undirected)\n",
    "# Each pair of nodes is connected in both directions\n",
    "edge_index = torch.tensor([[0, 1, 3, 3, 2], \n",
    "                           [1, 2, 2, 0, 0]], dtype=torch.long)  # Edges: 0-1, 1-2, 2-3, 3-0, 0-2\n",
    "edge_attr = torch.randint(0, 1, (edge_index.size(1), 19))\n",
    "# Apply the GCNConv layer to the node features\n",
    "out_features = gin_conv(x, edge_index, edge_attr)\n",
    "\n",
    "print(\"Original node features:\\n\", x)\n",
    "print(\"\\nTransformed node features:\\n\", out_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax, remove_self_loops\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "import numpy as np\n",
    "\n",
    "num_atom_type = 121 #including the extra motif tokens and graph token\n",
    "num_chirality_tag = 11  #degree\n",
    "\n",
    "num_bond_type = 7 \n",
    "num_bond_direction = 3 \n",
    "\n",
    "class GINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Extension of GIN aggregation to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): dimensionality of embeddings for nodes and edges.\n",
    "        embed_input (bool): whether to embed input or not. \n",
    "        \n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim, aggr = \"add\"):\n",
    "        super(GINConv, self).__init__()\n",
    "        #multi-layer perceptron\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.edge_embedding1 = torch.nn.Embedding(num_bond_type, emb_dim)\n",
    "        self.edge_embedding2 = torch.nn.Embedding(num_bond_direction, emb_dim)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n",
    "        self.aggr = aggr\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        #add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 2)\n",
    "        self_loop_attr[:,0] = 4 #bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim = 0)\n",
    "\n",
    "        edge_embeddings = self.edge_embedding1(edge_attr[:,0]) + self.edge_embedding2(edge_attr[:,1])\n",
    "\n",
    "        return self.propagate(edge_index[0], x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoleculeDataset(1513)\n"
     ]
    }
   ],
   "source": [
    "from KGGraph import MoleculeDataset\n",
    "task_type = 'classification'\n",
    "dataset = 'bace'\n",
    "dataset = MoleculeDataset(\"dataset/\" + task_type + \"/\" + dataset, dataset=dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(126)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dataset.x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 127  # Number of unique categories in your feature x\n",
    "emb_dim = 512\n",
    "x_embedding = torch.nn.Embedding(num_categories, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clamped = torch.clamp(x, 0, x_embedding.num_embeddings - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.6752,  -1.3753,  -9.0359,  ...,   2.0165,  27.0869,  29.7233],\n",
       "        [  6.1366,   1.4360, -11.5866,  ...,   3.0902,  23.8735,  28.4991],\n",
       "        [  6.1366,   1.4360, -11.5866,  ...,   3.0902,  23.8735,  28.4991],\n",
       "        ...,\n",
       "        [ -8.6951,  -0.3717, -11.8091,  ...,   9.5883,  51.8893,  52.0404],\n",
       "        [ -8.6951,  -0.3717, -11.8091,  ...,   9.5883,  51.8893,  52.0404],\n",
       "        [ -8.6951,  -0.3717, -11.8091,  ...,   9.5883,  51.8893,  52.0404]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embedding(x_clamped).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_embedding(x)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "x_embedding(x).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty((x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), emb_dim))\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# for i in range(x.size(1)):  # Iterate over the second dimension\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     print(i)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m embedding_ith \u001b[39m=\u001b[39m x_embedding(x[:, \u001b[39m2\u001b[39;49m])\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/labhhc/Documents/Workspace/D19/Thinh/Thesis/Github/KGGraph/test.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m embedding_ith\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/kgg/lib/python3.11/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "x_embeddings = torch.empty((x.size(0), emb_dim)).to(x.device).to(x.dtype)\n",
    "\n",
    "# for i in range(x.size(1)):  # Iterate over the second dimension\n",
    "#     print(i)\n",
    "embedding_ith = x_embedding(x[:, 2]).detach()\n",
    "embedding_ith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8772,  0.5183, -0.2573],\n",
      "        [ 0.0248,  1.2517,  0.3967]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embedding = torch.nn.Embedding(5, 3)\n",
    "\n",
    "# Create an input tensor with valid indices.\n",
    "valid_input_tensor = torch.tensor([1, 2], dtype=torch.long)  \n",
    "\n",
    "# Verify that all indices in the input tensor are within the valid range.\n",
    "if torch.all(valid_input_tensor >= 0) and torch.all(valid_input_tensor < embedding.num_embeddings):\n",
    "    output_tensor = embedding(valid_input_tensor)\n",
    "    print(output_tensor)\n",
    "else:\n",
    "    print(\"Invalid indices detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5203, -0.9386, -0.7461, -0.5588,  0.0097],\n",
      "        [-0.7428,  0.8891, -0.5622, -0.0936,  0.7392]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "embedding = nn.Embedding(10, 5)\n",
    "\n",
    "input_tensor = torch.tensor([1, 16, 7])\n",
    "\n",
    "# a boolean mask to filter out indices\n",
    "mask = (input_tensor < embedding.num_embeddings) & (input_tensor >= 0)\n",
    "\n",
    "# Apply the mask the input tensor\n",
    "valid_indices = input_tensor[mask]\n",
    "output_tensor = embedding(valid_indices)\n",
    "\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1360,  0.1091, -0.8151],\n",
      "        [ 1.3550,  0.1267,  1.5197],\n",
      "        [-0.0916,  0.7949, -0.7115],\n",
      "        [ 0.2716, -1.0548,  0.2645]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embedding = torch.nn.Embedding(5, 3)\n",
    "\n",
    "# Create an input tensor with potentially out-of-range indices.\n",
    "input_tensor = torch.tensor([1, 6, -1, 2.5], dtype=torch.long)\n",
    "\n",
    "# Using torch.clamp() to clamp the indices to the valid range.\n",
    "input_tensor_clamped = torch.clamp(input_tensor, 0, embedding.num_embeddings - 1)\n",
    "\n",
    "output_tensor = embedding(input_tensor_clamped)\n",
    "\n",
    "# Print the output tensor.\n",
    "print(output_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
