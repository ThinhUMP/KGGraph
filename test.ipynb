{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter, BatchNorm1d\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_scatter import scatter_add\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "\n",
    "unique_value_edge_attr = 2\n",
    "\n",
    "class GINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Extension of GIN aggregation to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): dimensionality of embeddings for nodes and edges.\n",
    "        embed_input (bool): whether to embed input or not. \n",
    "        \n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, emb_dim, aggr = \"add\"):\n",
    "        super(GINConv, self).__init__()\n",
    "        #multi-layer perceptron\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, 2*emb_dim),\n",
    "            torch.nn.BatchNorm1d(2*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2*emb_dim, 4*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4*emb_dim, 2*emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            )\n",
    "        self.edge_embedding = torch.nn.Embedding(unique_value_edge_attr, in_channels)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding.weight.data)\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #add self loops in the edge space\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        #add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), edge_attr.size(1))\n",
    "        self_loop_attr[:,-4] = 1 #bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim = 0)\n",
    "\n",
    "        edge_embeddings = torch.zeros((edge_attr.size(0), self.in_channels), dtype=torch.float).to(edge_attr.device).to(edge_attr.dtype)\n",
    "\n",
    "        for i in range(edge_attr.size(1)):  # Iterate over the second dimension\n",
    "            embedding_ith = self.edge_embedding(edge_attr[:, i]).clone().detach().to(edge_attr.device).to(edge_attr.dtype)\n",
    "            edge_embeddings += embedding_ith\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        print(x_j.shape, edge_attr.shape)\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        print(aggr_out.size())\n",
    "        aggr_out = torch.tensor(aggr_out, dtype=torch.float)\n",
    "        return self.mlp(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3]) torch.Size([9, 3])\n",
      "torch.Size([4, 3])\n",
      "Original node features:\n",
      " tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "\n",
      "Transformed node features:\n",
      " torch.Size([4, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868371/1986989193.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  aggr_out = torch.tensor(aggr_out, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Initialize the GCNConv layer\n",
    "# Transform from 3-dimensional features to 2-dimensional features\n",
    "gin_conv = GINConv(in_channels=3, emb_dim=6)\n",
    "\n",
    "# Define node features (4 nodes with 3 features each)\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], dtype=torch.float)\n",
    "\n",
    "# Define the edges in the graph (making it undirected)\n",
    "# Each pair of nodes is connected in both directions\n",
    "edge_index = torch.tensor([[0, 1, 3, 3, 2], \n",
    "                           [1, 2, 2, 0, 0]], dtype=torch.long)  # Edges: 0-1, 1-2, 2-3, 3-0, 0-2\n",
    "edge_attr = torch.randint(0, 1, (edge_index.size(1), 19))\n",
    "# Apply the GCNConv layer to the node features\n",
    "out_features = gin_conv(x, edge_index, edge_attr)\n",
    "\n",
    "print(\"Original node features:\\n\", x)\n",
    "print(\"\\nTransformed node features:\\n\", out_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax, remove_self_loops\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "import numpy as np\n",
    "\n",
    "num_atom_type = 121 #including the extra motif tokens and graph token\n",
    "num_chirality_tag = 11  #degree\n",
    "\n",
    "num_bond_type = 7 \n",
    "num_bond_direction = 3 \n",
    "\n",
    "class GINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Extension of GIN aggregation to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): dimensionality of embeddings for nodes and edges.\n",
    "        embed_input (bool): whether to embed input or not. \n",
    "        \n",
    "\n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim, aggr = \"add\"):\n",
    "        super(GINConv, self).__init__()\n",
    "        #multi-layer perceptron\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.edge_embedding1 = torch.nn.Embedding(num_bond_type, emb_dim)\n",
    "        self.edge_embedding2 = torch.nn.Embedding(num_bond_direction, emb_dim)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n",
    "        self.aggr = aggr\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "\n",
    "        #add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 2)\n",
    "        self_loop_attr[:,0] = 4 #bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim = 0)\n",
    "\n",
    "        edge_embeddings = self.edge_embedding1(edge_attr[:,0]) + self.edge_embedding2(edge_attr[:,1])\n",
    "\n",
    "        return self.propagate(edge_index[0], x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original node features:\n",
      "tensor([[ 0.2145, -2.9410,  0.2738,  1.5769],\n",
      "        [-0.5983, -0.7514, -0.8116,  0.2553],\n",
      "        [-0.6392, -0.0398, -1.6644,  1.0835]])\n",
      "\n",
      "Updated node features:\n",
      "tensor([[ 0.2887,  0.5924, -0.3227, -0.0814],\n",
      "        [ 0.6193,  0.6467, -0.9354, -0.4441],\n",
      "        [ 0.5508,  0.4071, -0.2276, -0.2344]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the number of bond types and directions\n",
    "num_bond_type = 7\n",
    "num_bond_direction = 3\n",
    "\n",
    "# Define the GINConv class (as you provided)\n",
    "\n",
    "# Initialize node features: 3 nodes with 4 features each\n",
    "x = torch.randn((3, 4))\n",
    "\n",
    "# Define edges: 0->1 and 1->2\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Define edge attributes: 2 edges with bond type and direction\n",
    "# Here we just use random integers for demonstration\n",
    "edge_attr = torch.randint(0, 3, (4, 2), dtype=torch.long)\n",
    "\n",
    "# Initialize the GINConv layer\n",
    "emb_dim = 4  # Embedding dimension\n",
    "gin_conv = GINConv(emb_dim)\n",
    "\n",
    "# Apply the GINConv layer\n",
    "out = gin_conv(x, edge_index, edge_attr)\n",
    "\n",
    "print(\"Original node features:\")\n",
    "print(x)\n",
    "print(\"\\nUpdated node features:\")\n",
    "print(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
